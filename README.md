# AI Adapter - Robust & Scalable Computer Vision Platform

A flexible, production-ready AI inference adapter designed for multi-model, multi-task computer vision applications. Built with extensibility and maintainability at its core.

## ğŸ¯ Project Overview

This project implements a **scalable AI adapter architecture** that decouples inference logic from application code, enabling easy integration of multiple AI models and tasks without tight coupling. The system currently supports YOLOv8-based person detection and counting, with a design that makes adding new models and tasks straightforward.

### Key Features

- âœ… **Multi-Model Support**: Plug-and-play architecture for multiple AI models
- âœ… **Multi-Task Per Model**: One model can serve multiple use cases
- âœ… **RESTful API**: FastAPI-based HTTP interface for easy integration
- âœ… **Dynamic Task Configuration**: Enable/disable tasks without code changes
- âœ… **ONNX Runtime**: Optimized inference with cross-platform compatibility
- âœ… **Active & Passive Modes**: Flexible camera handling with fallback support
- âœ… **Production-Ready**: NMS, confidence thresholding, and error handling built-in

---

## ğŸ—ï¸ Architecture & Design Philosophy

### The Model Handler Pattern

The core architectural pattern that makes this system robust and scalable:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FastAPI Server                       â”‚
â”‚                    (adapter/main.py)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Routes tasks via registry
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Model Registry (Dictionary)                 â”‚
â”‚   {                                                      â”‚
â”‚     "person_detection": YOLOv8Handler instance,         â”‚
â”‚     "person_counting": YOLOv8Handler instance,          â”‚
â”‚     "object_detection": FutureModelHandler instance     â”‚
â”‚   }                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YOLOv8Handler   â”‚   â”‚ Future Handlers  â”‚
â”‚                  â”‚   â”‚ (ResNet, etc.)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Detection      â”‚   â”‚ â€¢ Classification â”‚
â”‚ â€¢ Counting       â”‚   â”‚ â€¢ Segmentation   â”‚
â”‚ â€¢ NMS            â”‚   â”‚ â€¢ ...            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Principles

1. **Separation of Concerns**
   - **Adapter Layer**: HTTP interface and routing (`adapter/main.py`)
   - **Model Handlers**: Inference logic (`adapter/models/`)
   - **Configuration**: Centralized settings (`adapter/config.py`)
   - **Utilities**: Reusable helpers (`adapter/utils/`)

2. **Abstract Base Class Pattern**
   - All handlers inherit from `BaseModelHandler`
   - Enforces consistent interface: `get_supported_tasks()` and `infer()`
   - Makes adding new models trivial (just implement the interface)

3. **Task-Based Routing**
   - Tasks are first-class citizens (e.g., "person_detection", "person_counting")
   - One model can handle multiple tasks
   - Dynamic task registration at startup

4. **Configuration Over Code**
   - Enable/disable tasks via `ENABLED_TASKS` dict
   - Model paths in `MODEL_CONFIGS`
   - No code changes needed for common adjustments

---

## ğŸ“ Project Structure

```
adaplayer/
â”œâ”€â”€ adapter/                    # Core AI adapter
â”‚   â”œâ”€â”€ main.py                # FastAPI server & task routing
â”‚   â”œâ”€â”€ config.py              # Configuration & model registry
â”‚   â”œâ”€â”€ models/                # Model handler implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_handler.py   # Abstract base class
â”‚   â”‚   â””â”€â”€ yolov8_handler.py # YOLOv8 implementation
â”‚   â””â”€â”€ utils/                 # Helper utilities
â”‚       â””â”€â”€ image_utils.py    # Image loading & preprocessing
â”‚
â”œâ”€â”€ kavach/                    # Camera runner client
â”‚   â””â”€â”€ runner.py             # Capture frames & call adapter API
â”‚
â”œâ”€â”€ frames/                    # Runtime: captured frames stored here
â”‚   â””â”€â”€ camera_{id}/
â”‚       â””â”€â”€ latest.jpg
â”‚
â”œâ”€â”€ yolov8n.onnx              # YOLOv8 nano model (ONNX format)
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ run_task.bat             # Windows helper script
â””â”€â”€ README.md                # This file
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Webcam (optional, supports passive mode without camera)
- Windows/Linux/macOS

### 1. Installation

```bash
# Clone the repository
cd adaplayer

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Start the Adapter Server

```bash
uvicorn adapter.main:app --reload --port 9100
```

Expected output:
```
ğŸš€ Initializing AI Adapter...
  âœ“ Registered task: person_detection
  âœ“ Registered task: person_counting
âœ… Adapter ready with 2 active task(s)

INFO: Uvicorn running on http://127.0.0.1:9100
```

### 3. Run the Camera Runner

In a new terminal:

```bash
# Activate venv first
venv\Scripts\activate

# Run person detection
python kavach/runner.py --task person_detection

# Or run person counting
python kavach/runner.py --task person_counting

# List available tasks
python kavach/runner.py --list-tasks
```

**Alternative: Use the batch file (Windows)**
```bash
run_task.bat --task person_detection
```

---

## ğŸ“¡ API Reference

### Health Check
```http
GET /health
```
Returns: `{"status": "ok"}`

### Get Capabilities
```http
GET /capabilities
```
Returns:
```json
{
  "tasks": ["person_detection", "person_counting"]
}
```

### Run Inference
```http
POST /infer
Content-Type: application/json

{
  "task": "person_detection",
  "input": {
    "frame": {
      "uri": "kavach://frames/camera_0/latest.jpg"
    }
  }
}
```

**Response (Detection):**
```json
{
  "bbox": [100, 50, 200, 400],
  "confidence": 0.87,
  "message": "Person detected with confidence 0.87"
}
```

**Response (Counting):**
```json
{
  "count": 3,
  "confidence": 0.82,
  "detections": [
    {"bbox": [10, 20, 100, 200], "confidence": 0.85},
    {"bbox": [150, 30, 120, 220], "confidence": 0.81},
    {"bbox": [300, 40, 110, 210], "confidence": 0.79}
  ]
}
```

---

## ğŸ”§ Configuration

### Adjust Confidence Threshold

Edit `adapter/config.py`:
```python
CONFIDENCE_THRESHOLD = 0.5  # Adjust between 0.0 - 1.0
```

### Enable/Disable Tasks

```python
ENABLED_TASKS = {
    "person_detection": True,   # Set to False to disable
    "person_counting": True,
}
```

### Change Input Size

```python
INPUT_SIZE = 640  # YOLOv8 default, can be 320/416/640
```

---

## ğŸ§© Adding New Models

The architecture makes adding new models straightforward:

### Step 1: Create a Handler

Create `adapter/models/new_model_handler.py`:

```python
from .base_handler import BaseModelHandler
from typing import List, Dict, Any

class NewModelHandler(BaseModelHandler):
    def __init__(self, model_path: str):
        super().__init__(model_path)
        # Load your model here
        
    def get_supported_tasks(self) -> List[str]:
        return ["task1", "task2"]
    
    def infer(self, task: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        if task == "task1":
            return self._do_task1(input_data)
        elif task == "task2":
            return self._do_task2(input_data)
```

### Step 2: Register in Config

Edit `adapter/config.py`:

```python
MODEL_CONFIGS = {
    "yolov8n": {...},
    "new_model": {
        "path": "path/to/model.onnx",
        "handler_class": "NewModelHandler",
    }
}

ENABLED_TASKS = {
    "person_detection": True,
    "person_counting": True,
    "task1": True,  # New tasks
    "task2": True,
}
```

### Step 3: Import and Initialize

Edit `adapter/models/__init__.py`:
```python
from .new_model_handler import NewModelHandler
__all__ = [..., "NewModelHandler"]
```

Edit `adapter/main.py` startup:
```python
new_model_handler = NewModelHandler(MODEL_CONFIGS["new_model"]["path"])
for task in new_model_handler.get_supported_tasks():
    if ENABLED_TASKS.get(task, False):
        model_registry[task] = new_model_handler
```

That's it! Your new model is now integrated. ğŸ‰

---

## ğŸ¥ Camera Runner Features

### Active Mode
Captures frames from camera and sends to adapter:
```bash
python kavach/runner.py --task person_detection --camera 0 --interval 2.0
```

### Passive Mode
Automatically activates if camera is busy. Monitors file changes:
```
âš ï¸  Camera 0 is busy or unavailable.
ğŸ”„ Switching to PASSIVE MODE: Watching frames/camera_0/latest.jpg...
```

### Multiple Tasks
Run multiple tasks on the same frame:
```bash
python kavach/runner.py --task person_detection,person_counting
```

---

## ğŸ§ª Testing

### Verify Setup
```bash
python verify_setup.py
```

### Check Server Health
```bash
curl http://127.0.0.1:9100/health
```

### Test Inference
```bash
curl -X POST http://127.0.0.1:9100/infer \
  -H "Content-Type: application/json" \
  -d '{"task":"person_detection","input":{"frame":{"uri":"kavach://frames/camera_0/latest.jpg"}}}'
```

---

## ğŸ› ï¸ Technical Details

### Technologies Used

- **FastAPI**: Modern, high-performance web framework
- **ONNX Runtime**: Cross-platform, optimized inference engine
- **OpenCV**: Image processing and camera capture
- **YOLOv8**: State-of-the-art object detection
- **httpx**: Async HTTP client for runner
- **NumPy**: Numerical computing

### Key Implementations

1. **Non-Maximum Suppression (NMS)**
   - Removes duplicate detections
   - IoU threshold: 0.45
   - See: `YOLOv8Handler._apply_nms()`

2. **Dynamic Task Registration**
   - Tasks registered at startup based on config
   - Enables hot-swapping via server restart

3. **URI-Based Image Loading**
   - Custom URI scheme: `kavach://frames/...`
   - Decouples storage from inference logic

4. **Error Handling**
   - HTTPException for user-facing errors
   - Graceful degradation (passive mode)
   - Timeout handling in runner

---

## ğŸ“Š Performance

- **Inference Time**: ~50-150ms on CPU (YOLOv8n)
- **Detection Accuracy**: 0.5+ confidence threshold
- **NMS IoU**: 0.45 threshold
- **Memory**: ~200MB with model loaded

---

## ğŸ”® Future Enhancements

- [ ] GPU acceleration (CUDA/TensorRT)
- [ ] Multiple camera support
- [ ] WebSocket streaming
- [ ] Model versioning
- [ ] Metrics & monitoring
- [ ] Docker containerization
- [ ] Face recognition models
- [ ] Object tracking across frames

---

## ğŸ¤ Contributing

This architecture is designed for extensibility. To contribute:

1. Follow the Model Handler Pattern
2. Inherit from `BaseModelHandler`
3. Update configuration files
4. Add tests for new functionality
5. Document new tasks in this README

---

## ğŸ“ License

This project is open-source. Feel free to use and modify.

---

## ğŸ‘¨â€ğŸ’» Author

Built with a focus on **robust, scalable, and maintainable** code architecture.

### Design Goals Achieved:

âœ… **Robust**: Abstract interfaces, error handling, NMS, confidence thresholds  
âœ… **Scalable**: Add models without touching existing code  
âœ… **Maintainable**: Clear separation of concerns, configuration over code  
âœ… **Production-Ready**: FastAPI, ONNX Runtime, proper async handling  

---

## ğŸ“ Support

For questions or issues, check:
- Configuration: `adapter/config.py`
- Add models: See "Adding New Models" section
- API errors: Check `/health` endpoint
- Runner issues: Try `--list-tasks` flag

---

**Happy Coding! ğŸš€**
